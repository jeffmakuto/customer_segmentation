{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c12e50ef",
   "metadata": {},
   "source": [
    "# Customer Segmentation\n",
    "\n",
    "This notebook runs the full segmentation pipeline: loading the data (uses the `market` sheet), feature engineering, clustering (KMeans), evaluation and visualizations. It also summarizes findings and actionable recommendations so you can export or present results directly from the notebook.\n",
    "\n",
    "Assumptions:\n",
    "- The repository contains `data_processing.py`, `features.py`, and `pipeline.py` which this notebook may import.\n",
    "- Data source: `Supermarket Data.xlsx` downloaded from the Kaggle dataset into a cache; `data_processing.load_raw()` will prefer the `market` sheet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2fe570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T19:06:26.363927Z",
     "iopub.status.busy": "2025-10-27T19:06:26.363927Z",
     "iopub.status.idle": "2025-10-27T19:06:57.727312Z",
     "shell.execute_reply": "2025-10-27T19:06:57.727312Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/jeff/Projects/customer_segmentation/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# 1) Imports and environment\n",
    "import sys\n",
    "from pathlib import Path\n",
    "repo_root = Path('..').resolve()\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "# Ensure we can import packages from the managed virtual environment (.venv)\n",
    "venv_site_packages = repo_root / '.venv' / 'Lib' / 'site-packages'\n",
    "if venv_site_packages.exists() and str(venv_site_packages) not in sys.path:\n",
    "    sys.path.insert(0, str(venv_site_packages))\n",
    "\n",
    "print('Added repo root to sys.path:', repo_root)\n",
    "if venv_site_packages.exists():\n",
    "    print('Added .venv site-packages to sys.path:', venv_site_packages)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Helpers from this repo\n",
    "from data_processing import load_raw\n",
    "from features import build_transaction_features, build_store_aggregates\n",
    "\n",
    "# Plot settings\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "print('Notebook running with pandas', pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ff018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T19:06:57.727312Z",
     "iopub.status.busy": "2025-10-27T19:06:57.727312Z",
     "iopub.status.idle": "2025-10-27T19:07:04.379757Z",
     "shell.execute_reply": "2025-10-27T19:07:04.375833Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2) Load data\n",
    "\n",
    "# load_raw prefers the `market` sheet and handles column normalization\n",
    "raw_df = load_raw()\n",
    "print('Loaded dataframe shape:', raw_df.shape)\n",
    "raw_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00552f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T19:07:04.389827Z",
     "iopub.status.busy": "2025-10-27T19:07:04.387811Z",
     "iopub.status.idle": "2025-10-27T19:07:04.439282Z",
     "shell.execute_reply": "2025-10-27T19:07:04.435509Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3) Quick inspection\n",
    "print('Columns:', raw_df.columns.tolist())\n",
    "print('\\nMissing value counts (top 20):')\n",
    "print(raw_df.isnull().sum().sort_values(ascending=False).head(20))\n",
    "\n",
    "# Basic value counts for key categorical fields (if present)\n",
    "for c in ['supermarket','payment_type','category']:\n",
    "    if c in raw_df.columns:\n",
    "        print(f\"\\nValue counts for {c} (top 10):\")\n",
    "        print(raw_df[c].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837306c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T19:07:04.449357Z",
     "iopub.status.busy": "2025-10-27T19:07:04.447346Z",
     "iopub.status.idle": "2025-10-27T19:07:04.597133Z",
     "shell.execute_reply": "2025-10-27T19:07:04.594779Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4) Feature engineering\n",
    "\n",
    "features = build_transaction_features(raw_df)\n",
    "print('Features shape:', features.shape)\n",
    "features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01840ba4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T19:07:04.606840Z",
     "iopub.status.busy": "2025-10-27T19:07:04.605604Z",
     "iopub.status.idle": "2025-10-27T19:07:07.526515Z",
     "shell.execute_reply": "2025-10-27T19:07:07.526515Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4b) Quick feature distributions with contextual notes\n",
    "feature_cfg = {\n",
    "    'total': {\n",
    "        'title': 'Transaction total',\n",
    "        'xlabel': 'Total spend per basket (KES)',\n",
    "        'note': 'Most baskets cost <500; a few high-value trips create the right tail.',\n",
    "        'clip_quantile': 0.99\n",
    "    },\n",
    "    'no_of_items': {\n",
    "        'title': 'Basket size',\n",
    "        'xlabel': 'Number of items in a single transaction',\n",
    "        'note': 'Customers usually buy <5 items; larger baskets are uncommon stock-up trips.',\n",
    "        'clip_quantile': 0.995\n",
    "    },\n",
    "    'variation': {\n",
    "        'title': 'Category variety',\n",
    "        'xlabel': 'Distinct product categories purchased',\n",
    "        'note': 'Many baskets cover one category; some shoppers spread across 2–3.'\n",
    "    },\n",
    "    'hour': {\n",
    "        'title': 'Shopping hour',\n",
    "        'xlabel': 'Hour of day (24h clock)',\n",
    "        'note': 'Traffic builds from late morning and peaks between 15:00–19:00.'\n",
    "    },\n",
    "    'dayofweek': {\n",
    "        'title': 'Day of week',\n",
    "        'xlabel': '0=Mon … 6=Sun',\n",
    "        'note': 'Weekdays dominate, with a mid-week spike and lighter weekend traffic.'\n",
    "    },\n",
    "    'supermarket_freq': {\n",
    "        'title': 'Store popularity share',\n",
    "        'xlabel': 'Share of transactions attributed to the store',\n",
    "        'note': 'A few supermarkets capture most visits; long tail of low-volume outlets.'\n",
    "    }\n",
    "}\n",
    "\n",
    "fig_dist, axs = plt.subplots(2, 3, figsize=(15, 9))\n",
    "axs = axs.flatten()\n",
    "for ax, (col, cfg) in zip(axs, feature_cfg.items()):\n",
    "    if col not in features.columns:\n",
    "        ax.set_visible(False)\n",
    "        continue\n",
    "\n",
    "    series = features[col].dropna()\n",
    "    clip_q = cfg.get('clip_quantile')\n",
    "    if clip_q:\n",
    "        upper = series.quantile(clip_q)\n",
    "        series = series.clip(upper=upper)\n",
    "        ax.set_xlim(series.min(), upper)\n",
    "        ax.text(\n",
    "            0.98,\n",
    "            0.05,\n",
    "            f'Capped at {int(clip_q*100)}th percentile to highlight bulk of data',\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=8,\n",
    "            va='bottom',\n",
    "            ha='right',\n",
    "            color='#555555'\n",
    "        )\n",
    "\n",
    "    sns.histplot(x=series, ax=ax, kde=True, color='#1f77b4')\n",
    "    ax.set_title(cfg['title'])\n",
    "    ax.set_xlabel(cfg['xlabel'])\n",
    "    ax.set_ylabel('Number of transactions')\n",
    "    ax.grid(alpha=0.2)\n",
    "    ax.text(\n",
    "        0.02,\n",
    "        0.95,\n",
    "        cfg['note'],\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=9,\n",
    "        va='top',\n",
    "        ha='left',\n",
    "        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.65, edgecolor='none')\n",
    "    )\n",
    "\n",
    "fig_dist.suptitle('Feature distributions with interpretation', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7676b79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4c) Store popularity (top 10 supermarkets by transaction share)\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "store_counts = raw_df['supermarket'].fillna('UNKNOWN').value_counts()\n",
    "store_summary = (\n",
    "    pd.DataFrame({\n",
    "        'supermarket': store_counts.index,\n",
    "        'transactions': store_counts.values\n",
    "    })\n",
    ")\n",
    "store_summary['share'] = store_summary['transactions'] / store_summary['transactions'].sum()\n",
    "\n",
    "print('Top stores by transaction count:')\n",
    "store_summary.head(10)\n",
    "\n",
    "fig_store_pop, ax_store_pop = plt.subplots(figsize=(8, 4))\n",
    "subset = store_summary.head(10)\n",
    "ax_store_pop.barh(subset['supermarket'][::-1], subset['share'][::-1], color=sns.color_palette('viridis', len(subset)))\n",
    "ax_store_pop.set_title('Top 10 supermarkets by transaction share')\n",
    "ax_store_pop.set_xlabel('Share of all transactions')\n",
    "ax_store_pop.set_ylabel('Supermarket')\n",
    "ax_store_pop.xaxis.set_major_formatter(FuncFormatter(lambda val, pos: f\"{val:.0%}\"))\n",
    "for idx, (y, share) in enumerate(zip(subset['supermarket'][::-1], subset['share'][::-1])):\n",
    "    ax_store_pop.text(share + 0.002, idx, f\"{share:.1%}\", va='center', ha='left', fontsize=9)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83253d1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T19:07:07.526515Z",
     "iopub.status.busy": "2025-10-27T19:07:07.526515Z",
     "iopub.status.idle": "2025-10-27T19:07:12.366741Z",
     "shell.execute_reply": "2025-10-27T19:07:12.361449Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5) Scale features and evaluate candidate cluster counts\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(features)\n",
    "\n",
    "ks = range(2, 9)\n",
    "scores = {}\n",
    "inertias = {}\n",
    "for k in ks:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=20)\n",
    "    labels = km.fit_predict(X)\n",
    "    try:\n",
    "        s = silhouette_score(X, labels)\n",
    "    except Exception:\n",
    "        s = float('nan')\n",
    "    scores[k] = s\n",
    "    inertias[k] = km.inertia_\n",
    "    print(f'k={k}: silhouette={s:.4f}, inertia={km.inertia_:.2f}')\n",
    "\n",
    "best_k = max(scores, key=lambda kk: scores[kk] if not pd.isna(scores[kk]) else -1)\n",
    "\n",
    "fig_eval, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Inertia (Elbow) plot\n",
    "axes[0].plot(list(inertias.keys()), list(inertias.values()), marker='o', color='#1f77b4')\n",
    "axes[0].set_title('Elbow check via inertia')\n",
    "axes[0].set_xlabel('Number of clusters (k)')\n",
    "axes[0].set_ylabel('Within-cluster sum of squares (lower is tighter)')\n",
    "axes[0].grid(alpha=0.2)\n",
    "axes[0].annotate(\n",
    "    'Inertia drop slows beyond here',\n",
    "    xy=(best_k, inertias[best_k]),\n",
    "    xytext=(best_k + 0.5, inertias[best_k] + 2000),\n",
    "    arrowprops=dict(arrowstyle='->', color='black'),\n",
    "    fontsize=9,\n",
    "    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7, edgecolor='none')\n",
    ")\n",
    "\n",
    "# Silhouette plot\n",
    "axes[1].plot(list(scores.keys()), [scores[k] for k in scores], marker='o', color='#ff7f0e')\n",
    "axes[1].set_title('Silhouette score (higher separates clusters)')\n",
    "axes[1].set_xlabel('Number of clusters (k)')\n",
    "axes[1].set_ylabel('Average silhouette coefficient')\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].grid(alpha=0.2)\n",
    "axes[1].annotate(\n",
    "    f'Best k = {best_k}\\nSilhouette = {scores[best_k]:.2f}',\n",
    "    xy=(best_k, scores[best_k]),\n",
    "    xytext=(best_k + 0.5, min(scores[best_k] + 0.15, 0.95)),\n",
    "    arrowprops=dict(arrowstyle='->', color='black'),\n",
    "    fontsize=9,\n",
    "    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7, edgecolor='none')\n",
    ")\n",
    "\n",
    "fig_eval.suptitle('Comparing k choices before fitting the final model', fontsize=16)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11786c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T19:07:12.372809Z",
     "iopub.status.busy": "2025-10-27T19:07:12.372809Z",
     "iopub.status.idle": "2025-10-27T19:07:12.563349Z",
     "shell.execute_reply": "2025-10-27T19:07:12.561313Z"
    }
   },
   "outputs": [],
   "source": [
    "# 6) Fit final model with best k and inspect clusters\n",
    "best_k = max(scores, key=lambda kk: scores[kk] if not pd.isna(scores[kk]) else -1)\n",
    "print('Best k by silhouette:', best_k, 'score=', scores[best_k])\n",
    "\n",
    "km_final = KMeans(n_clusters=best_k, random_state=42, n_init=20)\n",
    "labels = km_final.fit_predict(X)\n",
    "raw_df['cluster'] = labels\n",
    "features['cluster'] = labels\n",
    "\n",
    "cluster_sizes = raw_df['cluster'].value_counts().sort_index()\n",
    "print('\\nCluster sizes:\\n', cluster_sizes)\n",
    "\n",
    "cluster_profiles = features.groupby('cluster').mean()\n",
    "cluster_profiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab569cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T19:07:12.572350Z",
     "iopub.status.busy": "2025-10-27T19:07:12.571334Z",
     "iopub.status.idle": "2025-10-27T19:07:13.556878Z",
     "shell.execute_reply": "2025-10-27T19:07:13.556878Z"
    }
   },
   "outputs": [],
   "source": [
    "# 6b) Visual summaries\n",
    "# Ensure output folder exists for any figures\n",
    "from matplotlib.lines import Line2D\n",
    "out = Path('..') / 'analysis_output'\n",
    "out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cluster size bar chart (use matplotlib directly to stay backend-agnostic)\n",
    "fig_cluster, ax_cluster = plt.subplots(figsize=(6, 4))\n",
    "ax_cluster.bar(cluster_sizes.index.astype(str), cluster_sizes.values, color=sns.color_palette('viridis', len(cluster_sizes)))\n",
    "ax_cluster.set_title('Cluster sizes')\n",
    "ax_cluster.set_xlabel('Cluster')\n",
    "ax_cluster.set_ylabel('Number of transactions')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Scatter of total vs no_of_items coloured by cluster without relying on pandas plotting\n",
    "fig_scatter = None\n",
    "if {'total', 'no_of_items', 'cluster'}.issubset(features.columns):\n",
    "    palette = sns.color_palette('viridis', len(cluster_sizes))\n",
    "    colour_lookup = {cluster: palette[idx] for idx, cluster in enumerate(cluster_sizes.index)}\n",
    "    colours = features['cluster'].map(colour_lookup)\n",
    "\n",
    "    fig_scatter, ax_scatter = plt.subplots(figsize=(6, 5))\n",
    "    ax_scatter.scatter(features['no_of_items'], features['total'], c=colours, alpha=0.7, edgecolor='k', linewidth=0.3)\n",
    "    ax_scatter.set_title('Total vs No. of items by cluster')\n",
    "    ax_scatter.set_xlabel('no_of_items')\n",
    "    ax_scatter.set_ylabel('total')\n",
    "    handles = [Line2D([0], [0], marker='o', color='w', markerfacecolor=colour_lookup[c], markersize=8, label=f'Cluster {c}') for c in cluster_sizes.index]\n",
    "    ax_scatter.legend(handles=handles, title='Cluster')\n",
    "    plt.tight_layout()\n",
    "\n",
    "print('Generated additional cluster charts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda67834",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T19:07:13.566300Z",
     "iopub.status.busy": "2025-10-27T19:07:13.565674Z",
     "iopub.status.idle": "2025-10-27T19:07:15.363755Z",
     "shell.execute_reply": "2025-10-27T19:07:15.363755Z"
    }
   },
   "outputs": [],
   "source": [
    "# 7) Save outputs\n",
    "out = Path('..') / 'analysis_output'\n",
    "out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# save labeled transactions and cluster summaries\n",
    "raw_df.to_csv(out / 'transactions_with_cluster_from_notebook.csv', index=False)\n",
    "cluster_profiles.to_csv(out / 'cluster_profiles_mean_from_notebook.csv')\n",
    "cluster_sizes.to_csv(out / 'cluster_sizes_from_notebook.csv')\n",
    "\n",
    "# save model and scaler\n",
    "joblib.dump(km_final, out / 'kmeans_model_from_notebook.joblib')\n",
    "joblib.dump(scaler, out / 'scaler_from_notebook.joblib')\n",
    "\n",
    "# persist figures if they exist\n",
    "# matplotlib.pyplot.Figure.savefig expects a str or file-like; convert Path -> str to satisfy type-checkers\n",
    "if 'fig_dist' in globals():\n",
    "    fig_dist.savefig(str(out / 'feature_distributions.png'), dpi=150, bbox_inches='tight')\n",
    "if 'fig_eval' in globals():\n",
    "    fig_eval.savefig(str(out / 'k_selection_diagnostics.png'), dpi=150, bbox_inches='tight')\n",
    "if 'fig_cluster' in globals():\n",
    "    fig_cluster.savefig(str(out / 'cluster_sizes_bar.png'), dpi=150, bbox_inches='tight')\n",
    "if 'fig_scatter' in globals() and fig_scatter is not None:\n",
    "    fig_scatter.savefig(str(out / 'cluster_scatter_total_items.png'), dpi=150, bbox_inches='tight')\n",
    "if 'fig_store_pop' in globals():\n",
    "    fig_store_pop.savefig(str(out / 'store_popularity_top10.png'), dpi=150, bbox_inches='tight')\n",
    "\n",
    "print('Saved outputs to', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa125f8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T19:07:15.363755Z",
     "iopub.status.busy": "2025-10-27T19:07:15.363755Z",
     "iopub.status.idle": "2025-10-27T19:07:15.443447Z",
     "shell.execute_reply": "2025-10-27T19:07:15.443447Z"
    }
   },
   "outputs": [],
   "source": [
    "# 8) Small cluster inspection and export\n",
    "out = Path('..') / 'analysis_output'\n",
    "out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "small_cluster_id = cluster_sizes.idxmin()\n",
    "small_rows = raw_df[raw_df['cluster'] == small_cluster_id]\n",
    "print(f'Smallest cluster is {small_cluster_id} with {len(small_rows)} rows')\n",
    "\n",
    "display(small_rows.head())\n",
    "summary = small_rows.describe(include='all')\n",
    "if hasattr(summary.index, 'infer_objects'):\n",
    "    summary.index = summary.index.infer_objects()\n",
    "display(summary)\n",
    "\n",
    "small_rows.to_csv(out / 'cluster_small_rows.csv', index=False)\n",
    "print('Saved smallest cluster rows to', out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
